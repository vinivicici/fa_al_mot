{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32c59dc7",
   "metadata": {},
   "source": [
    "# Embed & Cluster (CLIP + KMeans)\n",
    "\n",
    "제출/재현성을 위해 **경로·하이퍼파라미터를 상단 Config로 통일**하고, 임베딩/클러스터링/저장을 함수로 분리한 정리본입니다.\n",
    "\n",
    "- 입력: 이미지 폴더(기본: `filtered_images`)\n",
    "- 출력: `cluster_results.csv` (+ 선택: `embeddings.npy`, `umap_2d.npy`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 0) Config =====\n",
    "from pathlib import Path\n",
    "\n",
    "# 입력 이미지 폴더 (Windows 예시: r\"C:\\Users\\min\\Downloads\\filtered_images\")\n",
    "IMAGE_DIR = Path(r\"C:\\Users\\min\\Downloads\\filtered_images\")\n",
    "\n",
    "# 허용 확장자 / 재귀 탐색 여부\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
    "RECURSIVE = False\n",
    "\n",
    "# 출력 폴더/파일\n",
    "OUT_DIR = Path(\"./outputs\")\n",
    "OUT_CSV = OUT_DIR / \"cluster_results.csv\"\n",
    "OUT_EMB = OUT_DIR / \"embeddings.npy\"     # optional\n",
    "OUT_UMAP = OUT_DIR / \"umap_2d.npy\"       # optional\n",
    "\n",
    "# 모델/연산\n",
    "MODEL_NAME = \"ViT-B/32\"\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 클러스터링\n",
    "N_CLUSTERS = 21\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# (선택) 엘보우 메소드 탐색 범위\n",
    "RUN_ELBOW = True\n",
    "K_RANGE = range(10, 31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3562ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Imports =====\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baacc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2) Utilities =====\n",
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def list_images(image_dir, exts, recursive=False):\n",
    "    image_dir = Path(image_dir)\n",
    "    if not image_dir.exists():\n",
    "        raise FileNotFoundError(f\"IMAGE_DIR not found: {image_dir}\")\n",
    "\n",
    "    if recursive:\n",
    "        paths = [p for p in image_dir.rglob(\"*\") if p.suffix.lower() in exts]\n",
    "    else:\n",
    "        paths = [p for p in image_dir.glob(\"*\") if p.suffix.lower() in exts]\n",
    "\n",
    "    if not paths:\n",
    "        raise ValueError(f\"No images found in {image_dir} with extensions: {sorted(exts)}\")\n",
    "    return sorted(paths)\n",
    "\n",
    "def load_clip(model_name, device):\n",
    "    model, preprocess = clip.load(model_name, device=device, jit=False)\n",
    "    model.eval()\n",
    "    return model, preprocess\n",
    "\n",
    "def encode_images(paths, model, preprocess, device, batch_size=128):\n",
    "    all_emb = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(paths), batch_size), desc=\"Encoding images\"):\n",
    "            batch_paths = paths[i:i+batch_size]\n",
    "            batch_imgs = []\n",
    "            batch_ids = []\n",
    "\n",
    "            for p in batch_paths:\n",
    "                try:\n",
    "                    img = Image.open(p)\n",
    "                    if img.mode != \"RGB\":\n",
    "                        img = img.convert(\"RGB\")\n",
    "                    batch_imgs.append(preprocess(img))\n",
    "                    batch_ids.append(p.name)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Failed to load {p}: {e}\")\n",
    "\n",
    "            if not batch_imgs:\n",
    "                continue\n",
    "\n",
    "            batch_tensor = torch.stack(batch_imgs).to(device)\n",
    "            feats = model.encode_image(batch_tensor)\n",
    "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            all_emb.append(feats.cpu().numpy())\n",
    "            all_ids.extend(batch_ids)\n",
    "\n",
    "    if not all_emb:\n",
    "        raise RuntimeError(\"No embeddings were generated. Check image loading errors above.\")\n",
    "    emb = np.vstack(all_emb)\n",
    "    return emb, all_ids\n",
    "\n",
    "def run_elbow(embeddings, k_range, random_state=42):\n",
    "    inertia = []\n",
    "    for k in tqdm(list(k_range), desc=\"Elbow (inertia)\"):\n",
    "        km = KMeans(n_clusters=k, n_init=10, random_state=random_state)\n",
    "        km.fit(embeddings)\n",
    "        inertia.append(km.inertia_)\n",
    "    return inertia\n",
    "\n",
    "def cluster_kmeans(embeddings, n_clusters, random_state=42):\n",
    "    km = KMeans(n_clusters=n_clusters, n_init=10, random_state=random_state)\n",
    "    labels = km.fit_predict(embeddings)\n",
    "    return labels\n",
    "\n",
    "def reduce_umap(embeddings, random_state=42, n_neighbors=15, min_dist=0.1):\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=2,\n",
    "        random_state=random_state,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist\n",
    "    )\n",
    "    emb2d = reducer.fit_transform(embeddings)\n",
    "    return emb2d\n",
    "\n",
    "def plot_umap(emb2d, labels, title):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sc = plt.scatter(emb2d[:, 0], emb2d[:, 1], c=labels, s=10, alpha=0.7)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Cluster ID\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) Run pipeline =====\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "print(\"IMAGE_DIR:\", IMAGE_DIR)\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) images\n",
    "paths = list_images(IMAGE_DIR, IMAGE_EXTS, recursive=RECURSIVE)\n",
    "print(\"Num images:\", len(paths))\n",
    "\n",
    "# 2) model\n",
    "model, preprocess = load_clip(MODEL_NAME, device=device)\n",
    "print(\"Loaded CLIP:\", MODEL_NAME)\n",
    "\n",
    "# 3) embeddings\n",
    "embeddings, image_ids = encode_images(paths, model, preprocess, device=device, batch_size=BATCH_SIZE)\n",
    "print(\"Embeddings:\", embeddings.shape)\n",
    "\n",
    "# (optional) save raw embeddings for reproducibility\n",
    "np.save(OUT_EMB, embeddings)\n",
    "\n",
    "# 4) elbow\n",
    "if RUN_ELBOW:\n",
    "    inertia_values = run_elbow(embeddings, K_RANGE, random_state=RANDOM_STATE)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(list(K_RANGE), inertia_values, marker=\"o\", linestyle=\"--\")\n",
    "    plt.title(\"Elbow Method (Inertia)\")\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"Inertia\")\n",
    "    plt.xticks(list(K_RANGE))\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# 5) kmeans\n",
    "labels = cluster_kmeans(embeddings, N_CLUSTERS, random_state=RANDOM_STATE)\n",
    "print(\"KMeans done. k =\", N_CLUSTERS)\n",
    "\n",
    "# 6) umap 2D\n",
    "emb2d = reduce_umap(embeddings, random_state=RANDOM_STATE)\n",
    "np.save(OUT_UMAP, emb2d)\n",
    "\n",
    "plot_umap(emb2d, labels, title=f\"UMAP (CLIP {MODEL_NAME}) + KMeans (k={N_CLUSTERS})\")\n",
    "\n",
    "# 7) save results\n",
    "df = pd.DataFrame({\"image_id\": image_ids, \"cluster\": labels})\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved:\", OUT_CSV.resolve())\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
